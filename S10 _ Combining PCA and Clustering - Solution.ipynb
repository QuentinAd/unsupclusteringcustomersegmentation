{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br><h2>Session 10 | Combining PCA and Clustering</h2>\n",
    "<br><h3>THE ULTIMATE REVIEW FOR THE FINAL</h3>\n",
    "<h4>DAT-5303 | Machine Learning</h4>\n",
    "Chase Kusterer - Faculty of Analytics<br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h3>Part I: Conceptual Review</h3><br>\n",
    "Let's start by reviewing our key unsupervised learning concepts.<br><br>\n",
    "\n",
    "<strong>Principal Component Analysis</strong><br>\n",
    "Focuses on the variance between explanatory variables (i.e. their covariance).<br><br>\n",
    "\n",
    "Three situations where PCA is useful:\n",
    "1. Correlated Explanatory Variables (what's going on behind the scenes of the correlation)\n",
    "2. Dimensionality Reduction (grouping large variable sets into a more manageable number of factors)\n",
    "3. Latent Trait Exploration (measuring what cannot be measured directly)\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<strong>Clustering</strong><br>\n",
    "Divides observations into groups (i.e. clusters). Observations can be grouped based on their similarities or their differences.\n",
    "\n",
    "<br>\n",
    "<h3><u>Don't forget!!!</u></h3>\n",
    "\n",
    "1. Don't mix data concepts in the same algorithm (spending behavior, demographics, psychometrics, etc.). \n",
    "2. Scale your data.\n",
    "3. Interpretation is subjective, so spend ample time on this step.\n",
    "\n",
    "<br><br>\n",
    "<strong>Challenge 1</strong><br>\n",
    "Complete the code to import the necessary packages for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# importing packages\n",
    "########################################\n",
    "import _____            as pd                          # data science essentials\n",
    "import _____ as plt                         # fundamental data visualization\n",
    "import _____           as sns                         # enhanced visualizations\n",
    "from sklearn.preprocessing import _____        # standard scaler\n",
    "from sklearn.decomposition import _____                   # pca\n",
    "_____ scipy.cluster.hierarchy _____ dendrogram, linkage # dendrograms\n",
    "_____ sklearn.cluster         _____ KMeans              # k-means clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# importing packages\n",
    "########################################\n",
    "import pandas            as pd                          # data science essentials\n",
    "import matplotlib.pyplot as plt                         # fundamental data visualization\n",
    "import seaborn           as sns                         # enhanced visualizations\n",
    "from sklearn.preprocessing import StandardScaler        # standard scaler\n",
    "from sklearn.decomposition import PCA                   # pca\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage # dendrograms\n",
    "from sklearn.cluster         import KMeans              # k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Run the following code to load the dataset and set print options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# loading data and setting display options\n",
    "########################################\n",
    "# loading data\n",
    "customers_df = pd.read_excel('top_customers_subset.xlsx')\n",
    "\n",
    "\n",
    "# setting print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>User-Defined Functions</strong><br>\n",
    "Run the following code to load the user-defined functions used throughout this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# inertia\n",
    "########################################\n",
    "def interia_plot(data, max_clust = 50):\n",
    "    \"\"\"\n",
    "PARAMETERS\n",
    "----------\n",
    "data      : DataFrame, data from which to build clusters. Dataset should be scaled\n",
    "max_clust : int, maximum of range for how many clusters to check interia, default 50\n",
    "    \"\"\"\n",
    "\n",
    "    ks = range(1, max_clust)\n",
    "    inertias = []\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        # INSTANTIATING a kmeans object\n",
    "        model = KMeans(n_clusters = k)\n",
    "\n",
    "\n",
    "        # FITTING to the data\n",
    "        model.fit(data)\n",
    "\n",
    "\n",
    "        # append each inertia to the list of inertias\n",
    "        inertias.append(model.inertia_)\n",
    "\n",
    "\n",
    "\n",
    "    # plotting ks vs inertias\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    plt.plot(ks, inertias, '-o')\n",
    "\n",
    "\n",
    "    # labeling and displaying the plot\n",
    "    plt.xlabel('number of clusters, k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.xticks(ks)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "########################################\n",
    "# scree_plot\n",
    "########################################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 2</strong><br>\n",
    "Drop demographic information and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# dropping demographic information\n",
    "_____\n",
    "\n",
    "\n",
    "# scaling the data\n",
    "_____\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# dropping demographic information\n",
    "purchase_behavior = customers_df.drop(['Channel', 'Region'],\n",
    "                                      axis = 1)\n",
    "\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(purchase_behavior)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(purchase_behavior)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "purchases_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "purchases_scaled.columns = purchase_behavior.columns\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(purchase_behavior), '\\n\\n')\n",
    "print(pd.np.var(purchases_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "<h3>Part II: Principal Component Analysis</h3>\n",
    "\n",
    "Our process here is to:\n",
    "1. Develop a PCA model with no limit to principal components\n",
    "2. Analyze the <strong>explained_variance_ratio</strong> and the <strong>scree plot</strong>\n",
    "3. Decide how many components to RETAIN\n",
    "4. Build a new model with a limited number of principal components\n",
    "5. Interpret your results (what does each PC represent)\n",
    "\n",
    "<br>\n",
    "Remember, there may be some niche opportunities in smaller principal components. Be sure to check this before moving on because this may lead to excellent market opportunities.\n",
    "\n",
    "<br><br>\n",
    "<strong>Challenge 3</strong><br>\n",
    "Develop a PCA object with no limit to principal components and analyze its scree plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = _____(_____,\n",
    "          random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the scaled data\n",
    "customer_pca = _____._____(_____)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "_____(pca_object = _____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = PCA(n_components = None,\n",
    "          random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca = pca.fit_transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 4</strong><br>\n",
    "Reduce the number of principal components to a reasonable number based on the scree plot. Note that we do not need to rerun the scree plot. In this example, we will assume three PCs is a reasonable number based on the elbow in the scree plot. Also note that it would have been reasonable to retain enough PCs so that the cumulative explained variance ratio is greater than or equal to 0.80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_3 = _____(_____,\n",
    "            _____ = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca_3 = _____._____(_____)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_3 = PCA(n_components = 3,\n",
    "            random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca_3 = pca_3.fit_transform(purchases_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>OPTIONAL STEP</strong><br>Run the following code to compare the variance of the unlimited PCA model with the variance of the reduced PCA model. We are doing this in this script simply to show that the explain variance in each principal component does not change after dropping smaller PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### Max PC Model ###\n",
    "####################\n",
    "# transposing pca components (pc = MAX)\n",
    "factor_loadings = pd.DataFrame(pd.np.transpose(pca.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings = factor_loadings.set_index(purchases_scaled.columns)\n",
    "\n",
    "\n",
    "##################\n",
    "### 3 PC Model ###\n",
    "##################\n",
    "# transposing pca components (pc = 3)\n",
    "factor_loadings_3 = pd.DataFrame(pd.np.transpose(pca_3.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_3 = factor_loadings_3.set_index(purchases_scaled.columns)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(f\"\"\"\n",
    "MAX Components Factor Loadings\n",
    "------------------------------\n",
    "{factor_loadings.round(2)}\n",
    "\n",
    "\n",
    "3 Components Factor Loadings\n",
    "------------------------------\n",
    "{factor_loadings_3.round(2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 5</strong><br>\n",
    "Name your principal components based on the latent traits they reflect.<br>\n",
    "\n",
    "In this step, make sure to develop a story behind what each PC name represents. This is an ideal method for bridging the gap between the technical and non-technical people you are working with. Remember, by doing a good job here you are putting analytics at the forefront of strategic decision making, which is a great way to boost your value within an organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_3._____ = ['Herbivores',\n",
    "                           'Fancy Diners',\n",
    "                           'Winers']\n",
    "\n",
    "\n",
    "# checking the result\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_3.columns = ['Herbivores',\n",
    "                             'Fancy Diners',\n",
    "                             'Winers']\n",
    "\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 6</strong><br>\n",
    "Analyze the factor loadings for each customer in the dataset. Do this by identifying groups of customers that have very high or very low factor loadings in any given principal component. A good heuristic is to look for factor loadings that are greater than one standard deviation from the mean in absolute value. Develop a strategy for key groups that you identify.<br><br>\n",
    "\n",
    "<strong>Don't forget</strong> to look at both the positive and negative loadings.<br>\n",
    "<strong>Don't forget</strong> to calculate the percentage of your audience effected by each loading when developing your targeting strategy/new ideas.<br>\n",
    "<strong>Don't forget</strong> to also consider the proportion of revenue generated by each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "X_pca_reduced = pca_3.transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_pca_df = _____._____(_____)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "X_pca_reduced = pca_3.transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_pca_df = pd.DataFrame(X_pca_reduced)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "X_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br><h3>Part III: Clustering</h3><br>\n",
    "We are going to start by building an agglomerative clustering model. Remember, we are primarily interested in the <strong>dendrogram</strong> and the <strong>inertia plot</strong>. Our goal is to develop an idea as to how many clusters would be appropriate given our analysis of these tools, and then to apply this number of clusters to a k-Means model. Try to come away with 4-5 different numbers of clusters so that you have more options when applying k-Means. <strong>Before getting started, we need to rescale our data.</strong> The reason is that the variance amongst our features is no longer equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "pd.np.var(X_pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 7</strong><br>\n",
    "Complete the code to prepare a scaled version of the factor loadings (i.e. principal components) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = _____\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler._____(_____)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler._____(_____)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "pca_scaled = pd.DataFrame(_____)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "pca_scaled._____ = \n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(X_pca_df), '\\n\\n')\n",
    "print(pd.np.var(pca_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(X_pca_df)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled_pca = scaler.transform(X_pca_df)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "pca_scaled = pd.DataFrame(X_scaled_pca)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "pca_scaled.columns = ['Herbivores',\n",
    "                      'Fancy Diners',\n",
    "                      'Winers']\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(X_pca_df), '\\n\\n')\n",
    "print(pd.np.var(pca_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Run the following code to develop a dendrogram. Our goal here is to understand how many clusters to build using k-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# grouping data based on Ward distance\n",
    "standard_mergings_ward = linkage(y = pca_scaled,\n",
    "                                 method = 'ward')\n",
    "\n",
    "\n",
    "# setting plot size\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# developing a dendrogram\n",
    "dendrogram(Z = standard_mergings_ward,\n",
    "           leaf_rotation = 90,\n",
    "           leaf_font_size = 6)\n",
    "\n",
    "\n",
    "# saving and displaying the plot\n",
    "plt.savefig('standard_hierarchical_clust_ward.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 8</strong><br>\n",
    "Develop a code to analyze the inertia plot. Our goal here is to develop more candidates for the number of clusters we might want to develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# calling the inertia_plot() function\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# calling the inertia_plot() function\n",
    "interia_plot(data = pca_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 9</strong><br>\n",
    "This is where we test our candidate number of clusters. When we find a clustering that we like, we move forward. For this example, let's assume we converged on a solution of three clusters.<br><br>\n",
    "<strong>Don't forget</strong> that the appropriate number of clusters does not have to be the same as the number of principal components that were retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a k-Means object with five clusters\n",
    "customers_k_pca = _____(n_clusters = 3,\n",
    "                        random_state = 802)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca._____(_____)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = _____._____({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a k-Means object with five clusters\n",
    "customers_k_pca = KMeans(n_clusters = 3,\n",
    "                         random_state = 802)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca.fit(pca_scaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 10</strong><br>\n",
    "Finish the code to display the centroids (mean values) for each cluster. Interpret their meaning. This is also a place where you may want to (optionally) name your clusters and develop back stories for ideal members of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# storing cluster centers\n",
    "centroids_pca = customers_k_pca._____\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_pca_df = _____._____(_____)\n",
    "\n",
    "\n",
    "# renaming principal components\n",
    "centroids_pca_df._____ = _____\n",
    "\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_pca_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# storing cluster centers\n",
    "centroids_pca = customers_k_pca.cluster_centers_\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_pca_df = pd.DataFrame(centroids_pca)\n",
    "\n",
    "\n",
    "# renaming principal components\n",
    "centroids_pca_df.columns = ['Herbivores',\n",
    "                            'Fancy Diners',\n",
    "                            'Winers']\n",
    "\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_pca_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 11</strong><br>\n",
    "Complete the code to concatenate channel, region, and PCA components into one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# concatinating cluster memberships with principal components\n",
    "clst_pca_df = _____._____([_____,\n",
    "                          _____],\n",
    "                          axis = _____)\n",
    "\n",
    "\n",
    "# checking results\n",
    "clst_pca_df\n",
    "\n",
    "\n",
    "# concatenating demographic information with pca-clusters\n",
    "final_pca_clust_df = _____._____([customers_df.loc[ : , ['Channel', 'Region']],\n",
    "                                  clst_pca_df],\n",
    "                                  axis = _____)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "final_pca_clust_df.columns = ['Channel',\n",
    "                              'Region',\n",
    "                              'Cluster',\n",
    "                              'Herbivores',\n",
    "                              'Fancy Diners',\n",
    "                              'Winers']\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(final_pca_clust_df.head(n = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# concatenating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([customers_kmeans_pca,\n",
    "                         X_pca_df],\n",
    "                         axis = 1)\n",
    "\n",
    "\n",
    "# checking results\n",
    "clst_pca_df\n",
    "\n",
    "\n",
    "# concatenating demographic information with pca-clusters\n",
    "final_pca_clust_df = pd.concat([customers_df.loc[ : , ['Channel', 'Region']],\n",
    "                                clst_pca_df],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "final_pca_clust_df.columns = ['Channel',\n",
    "                              'Region',\n",
    "                              'Cluster',\n",
    "                              'Herbivores',\n",
    "                              'Fancy Diners',\n",
    "                              'Winers']\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(final_pca_clust_df.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Run the following code to add labels to categorical variables. If you (optionally) named your clusters, make sure to label these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# renaming channels\n",
    "channel_names = {1 : 'Online',\n",
    "                 2 : 'Mobile'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['Channel'].replace(channel_names, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# renaming regions\n",
    "region_names = {1 : 'Alameda',\n",
    "                2 : 'San Francisco',\n",
    "                3 : 'Contra Costa'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['Region'].replace(region_names, inplace = True)\n",
    "\n",
    "\n",
    "# renaming regions\n",
    "cluster_names = {0 : 'Cluster 1',\n",
    "                 1 : 'Cluster 2',\n",
    "                 2 : 'Cluster 3'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['Cluster'].replace(cluster_names, inplace = True)\n",
    "\n",
    "\n",
    "# adding a productivity step\n",
    "data_df = final_pca_clust_df\n",
    "\n",
    "\n",
    "# checking results\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<h3>Part IV: Analyze with Demographics</h3><br>\n",
    "Now that we've completed all of our preparation through machine learning, we can analyze our results with demographics and other data.<br><br>\n",
    "<strong>Pause before this step</strong> so that you can consider all of the hypotheses and assumptions you have made up to this point. Also consider all of the assumptions your organization is making. For example, if the company is convinced of a particular trend, the following is a good opportunity to validate/negate that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# Channel\n",
    "########################\n",
    "\n",
    "# Herbivores\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'Channel',\n",
    "            y = 'Herbivores',\n",
    "            hue = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Fancy Diners\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'Channel',\n",
    "            y = 'Fancy Diners',\n",
    "            hue = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Winers\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'Channel',\n",
    "            y = 'Winers',\n",
    "            hue = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "# Region\n",
    "########################\n",
    "\n",
    "# Herbivores\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'Region',\n",
    "            y = 'Herbivores',\n",
    "            hue = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Fancy Diners\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'Region',\n",
    "            y = 'Fancy Diners',\n",
    "            hue = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Winers\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'Region',\n",
    "            y = 'Winers',\n",
    "            hue = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "~~~\n",
    " __     __                               _        _ _   _ \n",
    " \\ \\   / /                              | |      (_) | | |\n",
    "  \\ \\_/ /__  _   _   _ __ ___   __ _  __| | ___   _| |_| |\n",
    "   \\   / _ \\| | | | | '_ ` _ \\ / _` |/ _` |/ _ \\ | | __| |\n",
    "    | | (_) | |_| | | | | | | | (_| | (_| |  __/ | | |_|_|\n",
    "    |_|\\___/ \\__,_| |_| |_| |_|\\__,_|\\__,_|\\___| |_|\\__(_)\n",
    "                                                          \n",
    "                                                          \n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
