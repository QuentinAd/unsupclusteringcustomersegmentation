{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br><h2>Session 8b | Principal Component Analysis</h2>\n",
    "<h4>DAT-5303 | Machine Learning</h4>\n",
    "Chase Kusterer - Faculty of Analytics<br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h3>Part I: Introduction and Preparation</h3><br>\n",
    "\n",
    "<strong>A Note on the Dataset</strong><br>\n",
    "The dataset in this script represents the annual spending of a subset of the top customers for Apprentice Chef, Inc. The monetary units are unknown, and the demographic information related to each client is as follows:<br><br><br>\n",
    "<u>Channel</u><br>\n",
    "\n",
    "1. Online\n",
    "2. Mobile App\n",
    "\n",
    "<br>\n",
    "<u>Region</u><br>\n",
    "\n",
    "1. Alameda\n",
    "2. San Francisco\n",
    "3. Contra Costa\n",
    "\n",
    "<br><br>\n",
    "Run the following code to import necessary packages, load data, and set display options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# importing packages\n",
    "########################################\n",
    "import pandas            as pd  # data science essentials\n",
    "import matplotlib.pyplot as plt                  # fundamental data visualization\n",
    "import seaborn           as sns                  # enhanced visualization\n",
    "from sklearn.preprocessing import StandardScaler # standard scaler\n",
    "from sklearn.decomposition import PCA            # pca\n",
    "\n",
    "\n",
    "########################################\n",
    "# loading data and setting display options\n",
    "########################################\n",
    "# loading data\n",
    "customers_df = pd.read_excel('top_customers_subset.xlsx')\n",
    "\n",
    "\n",
    "# setting print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>User-Defined Functions</strong><br>\n",
    "Run the following code to load the user-defined functions used throughout this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# scree_plot\n",
    "########################################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 1</strong><br>\n",
    "Write code to check information about non-missing values and data types for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# checking information about each column\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# checking information about each column\n",
    "customers_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 2</strong><br>\n",
    "Write code to create a summary of descriptive statistics for each column, rounded to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# summary of decriptive statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# summary of decriptive statistics\n",
    "customers_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 3</strong><br>\n",
    "Write code to create print the value counts for channel and region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# value counts for channel\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# value counts for region\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# value counts for channel\n",
    "print(customers_df['Channel'].value_counts())\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# value counts for region\n",
    "print(customers_df['Region'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 4</strong><br>\n",
    "Write code to display the first ten rows of <strong>customers_df</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# displaying first ten rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# displaying first ten rows of the dataset\n",
    "customers_df.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Datasets with Features for Different Purposes</strong><br>\n",
    "Notice from the outputs above that the dataset contains demographic data (channel and region) as well purchasing data (spending per category). In unsupervised learning, feature types such as these should not be used together in the same algorithm. Demographic data is extremely different from purchasing data, and their concatenation would bias the results of an analysis. Instead, if a problem requires unsupervised learning and demographic data is present in the dataset, a best practice is to remove the demographic data before building an algorithm. Later, demographic data can be used to compare results.<br><br><br>\n",
    "<strong>PCA and Scaling</strong><br>\n",
    "As with KNN, explanatory variables should be scaled before developing a principal component analysis algorithm.<br><br><br>\n",
    "<strong>Challenge 5</strong><br>\n",
    "Complete the following in the code below:<br>\n",
    "\n",
    "* drop demographic data and store the result as purchase_behavior\n",
    "* instantiate a StandardScaler() object\n",
    "* fit the scaler object to purchase_behavior\n",
    "* transform purchase_behavior using the scaler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# scaling (normalizing) variables before correlation analysis\n",
    "\n",
    "# dropping demographic information\n",
    "purchase_behavior = customers_df._____(_____,\n",
    "                                      axis = 1)\n",
    "\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = _____\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler._____(_____)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler._____(_____)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "purchases_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "purchases_scaled.columns = purchase_behavior.columns\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(purchase_behavior), '\\n\\n')\n",
    "print(pd.np.var(purchases_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# scaling (normalizing) variables before correlation analysis\n",
    "\n",
    "# dropping demographic information\n",
    "purchase_behavior = customers_df.drop(['Channel', 'Region'],\n",
    "                                      axis = 1)\n",
    "\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(purchase_behavior)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(purchase_behavior)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "purchases_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "purchases_scaled.columns = purchase_behavior.columns\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(purchase_behavior), '\\n\\n')\n",
    "print(pd.np.var(purchases_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<h3>Part II: Exploratory Data Analysis</h3><br>\n",
    "Run the following code to produce histograms for all features related to purchasing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "\n",
    "\n",
    "# initializing a counter\n",
    "count = 0\n",
    "\n",
    "\n",
    "# looping to create visualizations\n",
    "for col in purchases_scaled:\n",
    "\n",
    "    # condition to break\n",
    "    if count == 6:\n",
    "        break\n",
    "    \n",
    "    # increasing count\n",
    "    count += 1\n",
    "    \n",
    "    # preparing histograms\n",
    "    plt.subplot(2, 3, count)\n",
    "    sns.distplot(a = purchases_scaled[col],\n",
    "                 hist = True,\n",
    "                 kde = True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('purchases_scaled_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 6</strong><br>\n",
    "Fill in the blanks below to develop a correlation heatmap of the scaled purchasing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# setting plot size\n",
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "\n",
    "# developing a correlation matrix object\n",
    "df_corr = _____._____.round(2)\n",
    "\n",
    "\n",
    "# creating a correlation heatmap\n",
    "sns.heatmap(_____,\n",
    "            cmap = 'coolwarm',\n",
    "            square = True,\n",
    "            annot = True)\n",
    "\n",
    "\n",
    "# saving and displaying the heatmap\n",
    "plt.savefig('top_customers_correlation_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# setting plot size\n",
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "\n",
    "# developing a correlation matrix object\n",
    "df_corr = purchases_scaled.corr().round(2)\n",
    "\n",
    "\n",
    "# creating a correlation heatmap\n",
    "sns.heatmap(df_corr,\n",
    "            cmap = 'coolwarm',\n",
    "            square = True,\n",
    "            annot = True)\n",
    "\n",
    "\n",
    "# saving and displaying the heatmap\n",
    "plt.savefig('top_customers_correlation_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Notice that only a few (Pearson) correlations have an absolute value above 0.50. This makes the dataset a good candidate for PCA. As such, we may be able to explain a high degree of variance with a small number of principal components.<br><br>\n",
    "\n",
    "<h3>Part III: Principal Component Analysis</h3><br>\n",
    "Principal component analysis is primarily conducted in three situations:<br>\n",
    "\n",
    "<u>Correlated Explanatory Variables</u><br>\n",
    "Model building with correlated explanatory variables (i.e. <a href=\"https://en.wikipedia.org/wiki/Multicollinearity\">multicollinearity</a>) is a violation of one of the key assumptions of generalized linear models.<br><br>\n",
    "\n",
    "<u>Dimensionality Reduction</u><br>\n",
    "This is commonly conducted when a dataset has a large amount of explanatory variables (i.e. every unique click a user has made on a website). Techniques like PCA allow features to be transformed into principal components, (potentially) reducing the number of features needed to explain a high degree of variance.<br><br>\n",
    "\n",
    "<u>Latent Trait Exploration</u><br>\n",
    "Understanding factors that cannot be measured directly through measurable constructs.<br><br>\n",
    "\n",
    "<strong>Challenge 7</strong><br>\n",
    "Complete the code to instantiate, fit, and transform a PCA model with no limits to its number of principal components. Make sure to use the scaled dataset for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = _____(n_components = None,\n",
    "            random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the scaled data\n",
    "customer_pca = _____._____(_____)\n",
    "\n",
    "\n",
    "# comparing dimensions of each DataFrame\n",
    "print(\"Original shape:\", X_scaled.shape)\n",
    "print(\"PCA shape     :\",  customer_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = PCA(n_components = None,\n",
    "                   random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the scaled data\n",
    "customer_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "# comparing dimensions of each DataFrame\n",
    "print(\"Original shape:\", X_scaled.shape)\n",
    "print(\"PCA shape     :\",  customer_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<h3>Part IV: Evaluating PCA Algorithms</h3><br>\n",
    "As can be observed from above, the shape of the data did not change. However, the original DataFrame contains features, whereas the new DataFrame contains principal components. Before analyzing the factor loadings of each principal component, it is important to check each component's explained variance ratio. Also note that the sum of all explained variance ratios should sum to 1.0.<br><br><br>\n",
    "<strong>Challenge 8</strong><br>\n",
    "Write code to loop over each principal component, printing its component number as well as its <strong>explained_variance_ratio_</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number = 0\n",
    "\n",
    "# looping over each principal component\n",
    "_____ variance _____ pca._____:\n",
    "    component_number += _____\n",
    "    \n",
    "    print(f\"PC {_____} : {_____.round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number = 0\n",
    "\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca.explained_variance_ratio_:\n",
    "    component_number += 1\n",
    "    print(f\"PC {component_number} : {variance.round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Challenge 9</strong><br>\n",
    "Write code to print the sum of all explained variance ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# printing the sum of all explained variance ratios\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# printing the sum of all explained variance ratios\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<h3>Scree Plots</h3><br>\n",
    "One useful tool to visualize the explained variance of each principal component is the scree plot. Our goal in analyzing this plot is to look for a point where there is a drop in the marginal return of explained variance. In other words, we are looking for an \"elbow\" in the plot, where the line connecting each principal component becomes less steep.<br><br><br>\n",
    "<strong>Challenge 10</strong><br>\n",
    "Call the scree_plot function on the PCA object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# calling the scree_plot function\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<h3>Part V: Interpreting Principal Components and Persona Development</h3><br>\n",
    "Principal components are essentially \"bundles\" of various parts of the explanatory variables that were used when building an algorithm. Note that each principal component is not directly measurable, but can be measured indirectly by analyzing its <strong>factor loadings</strong>. In other words, we can interpret the meaning of each principal component by looking into which features are strongly correlated with it.<br><br>\n",
    "Run the following code and analyze the resulting correlation map between the original features and the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# setting plot size\n",
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "\n",
    "\n",
    "# developing a PC to feature heatmap\n",
    "sns.heatmap(pca.components_, \n",
    "            cmap = 'coolwarm',\n",
    "            square = True,\n",
    "            annot = True,\n",
    "            linewidths = 0.1,\n",
    "            linecolor = 'black')\n",
    "\n",
    "\n",
    "# setting more plot options\n",
    "plt.yticks([0, 1, 2, 3, 4, 5],\n",
    "           [\"PC 1\", \"PC 2\", \"PC 3\", \"PC 4\", \"PC 5\", \"PC 6\"])\n",
    "\n",
    "plt.xticks(range(0, 6),\n",
    "           customers_df.columns[2:],\n",
    "           rotation=60,\n",
    "           ha='left')\n",
    "\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Principal Component\")\n",
    "\n",
    "\n",
    "# displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Each observation in the dataset is a customer of Apprentice Chef, Inc. Therefore, each principal component can be thought of as a <a href=\"https://www.lexico.com/en/definition/persona\">persona</a> to aid in interpretation. Naming personas is subjective and often benefits from working with others.<br><br><br>\n",
    "<strong>Challenge 11</strong><br>\n",
    "Run the following code. With your team, analyze the factor loadings and develop a persona for each principal component. When finished, rename the columns of the table with your team's persona names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# transposing pca components\n",
    "factor_loadings_df = pd.DataFrame(pd.np.transpose(pca.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_df = factor_loadings_df.set_index(purchases_scaled.columns)\n",
    "\n",
    "\n",
    "# checking the result\n",
    "print(factor_loadings_df)\n",
    "\n",
    "\n",
    "# saving to Excel\n",
    "factor_loadings_df.to_excel('customer_factor_loadings.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_df._____ = _____\n",
    "\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_df.columns = ['Herbivores',\n",
    "                              'Fancy Diners',\n",
    "                              'Winers',\n",
    "                              'Traditionalists',\n",
    "                              'Vegans',\n",
    "                              'Veggie Lovers']\n",
    "\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "<strong>Customer-Level Personas</strong><br>\n",
    "Earlier in this script we instantiated, fit, and transformed the dataset's original features into principal components:<br><br>\n",
    "\n",
    "~~~\n",
    "# FITTING and TRANSFORMING the scaled data\n",
    "customer_pca = pca.fit_transform(X_scaled)\n",
    "~~~\n",
    "\n",
    "<br>\n",
    "Now that we have developed personas, we can analyze how much each customer fits into each group. Run the following code to view the personas and factor loadings for each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# converting into a DataFrame \n",
    "customer_pca = pd.DataFrame(customer_pca)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "customer_pca.columns = factor_loadings_df.columns\n",
    "\n",
    "\n",
    "# checking results\n",
    "customer_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "Digging deeper into the DataFrame above can unearth key findings and market opportunities. <strong>This is something expected of you on your final.</strong> As an example, if we were exploring the market potential for customers with a standard deviation of one or above in the Vegan persona, we could do so through subsetting, as in the following code. Try this on other personas and enjoy the exploration :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "customer_pca['Vegans'][customer_pca['Vegans'] > 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "~~~\n",
    " ,--.-,,-,--,             .-._            _,---.                                        \n",
    "/==/  /|=|  |.--.-. .-.-./==/ \\  .-._ _.='.'-,  \\  .-.,.---.  ,--.-.  .-,--.            \n",
    "|==|_ ||=|, /==/ -|/=/  ||==|, \\/ /, /==.'-     / /==/  `   \\/==/- / /=/_ /             \n",
    "|==| ,|/=| _|==| ,||=| -||==|-  \\|  /==/ -   .-' |==|-, .=., \\==\\, \\/=/. /              \n",
    "|==|- `-' _ |==|- | =/  ||==| ,  | -|==|_   /_,-.|==|   '='  /\\==\\  \\/ -/               \n",
    "|==|  _     |==|,  \\/ - ||==| -   _ |==|  , \\_.' )==|- ,   .'  |==|  ,_/                \n",
    "|==|   .-. ,\\==|-   ,   /|==|  /\\ , \\==\\-  ,    (|==|_  . ,'.  \\==\\-, /                 \n",
    "/==/, //=/  /==/ , _  .' /==/, | |- |/==/ _  ,  //==/  /\\ ,  ) /==/._/                  \n",
    "`--`-' `-`--`--`..---'   `--`./  `--``--`------' `--`-`--`--'  `--`-`                   \n",
    "     _,---.     _,.---._                                                                \n",
    "  .-`.' ,  \\  ,-.' , -  `.   .-.,.---.                                                  \n",
    " /==/_  _.-' /==/_,  ,  - \\ /==/  `   \\                                                 \n",
    "/==/-  '..-.|==|   .=.     |==|-, .=., |                                                \n",
    "|==|_ ,    /|==|_ : ;=:  - |==|   '='  /                                                \n",
    "|==|   .--' |==| , '='     |==|- ,   .'                                                 \n",
    "|==|-  |     \\==\\ -    ,_ /|==|_  . ,'.                                                 \n",
    "/==/   \\      '.='. -   .' /==/  /\\ ,  )                                                \n",
    "`--`---'        `--`--''   `--`-`--`--'                                                 \n",
    "   ,-,--.                _,.----.    _,.----.       ,----.    ,-,--.    ,-,--.   .=-.-. \n",
    " ,-.'-  _\\ .--.-. .-.-..' .' -   \\ .' .' -   \\   ,-.--` , \\ ,-.'-  _\\ ,-.'-  _\\ /==/_ / \n",
    "/==/_ ,_.'/==/ -|/=/  /==/  ,  ,-'/==/  ,  ,-'  |==|-  _.-`/==/_ ,_.'/==/_ ,_.'|==|, |  \n",
    "\\==\\  \\   |==| ,||=| -|==|-   |  .|==|-   |  .  |==|   `.-.\\==\\  \\   \\==\\  \\   |==|  |  \n",
    " \\==\\ -\\  |==|- | =/  |==|_   `-' \\==|_   `-' \\/==/_ ,    / \\==\\ -\\   \\==\\ -\\  /==/. /  \n",
    " _\\==\\ ,\\ |==|,  \\/ - |==|   _  , |==|   _  , ||==|    .-'  _\\==\\ ,\\  _\\==\\ ,\\ `--`-`   \n",
    "/==/\\/ _ ||==|-   ,   |==\\.       |==\\.       /|==|_  ,`-._/==/\\/ _ |/==/\\/ _ | .=.     \n",
    "\\==\\ - , //==/ , _  .' `-.`.___.-' `-.`.___.-' /==/ ,     /\\==\\ - , /\\==\\ - , /:=; :    \n",
    " `--`---' `--`..---'                           `--`-----``  `--`---'  `--`---'  `=`                                                                      \n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
